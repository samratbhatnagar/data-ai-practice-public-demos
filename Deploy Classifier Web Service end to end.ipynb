{"cells":[{"cell_type":"markdown","source":["#Install the Azure ML SDK on your Azure Databricks Cluster"],"metadata":{}},{"cell_type":"markdown","source":["The `Azure Machine Learning Python SDK` is required for leveraging the experimentation, model management and model deployment capabilities of Azure Machine Learning services.\n\nIf your cluster is not already provisioned with the Azure Machine Learning Python SDK, you easily add it to your cluster by adding the following libraries. \n\nFor reference, to use this notebook in your own Databricks environment, you will need to create libraries, using the [Create Library](https://docs.azuredatabricks.net/user-guide/libraries.html) interface in Azure Databricks, for the following and attach them to your cluster:\n\n**azureml-sdk**\n* Source: Upload Python Egg or PyPi\n* PyPi Name: `azureml-sdk[databricks]`\n* Select Install Library"],"metadata":{}},{"cell_type":"markdown","source":["Verify that the Azure ML SDK is installed on your cluster by running the following cell:"],"metadata":{}},{"cell_type":"code","source":["import azureml.core\nazureml.core.VERSION"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">1</span><span class=\"ansired\">]: </span>&apos;0.1.68&apos;\n</div>"]}}],"execution_count":4},{"cell_type":"markdown","source":["If you see a version number output in the above cell, your cluster is ready to go."],"metadata":{}},{"cell_type":"markdown","source":["#Initialize Azure ML Workspace\n\nIn this notebook, you will use the Azure Machine Learning SDK to create a new Azure Machine Learning Workspace in your Azure Subscription.\n\nPlease specify the Azure subscription Id, resource group name, workspace name, and the region in which you want to create the Azure Machine Learning Workspace. \n\nYou can get the value of your Azure subscription ID from the Azure Portal, and then selecting Subscriptions from the menu on the left.\n\nFor the `resource_group`, use the name of the resource group that contains your Azure Databricks Workspace. \n\nNOTE: If you provide a resource group name that does not exist, the resource group will be automatically created. This may or may not succeed in your environment, depending on the permissions you have on your Azure Subscription."],"metadata":{}},{"cell_type":"code","source":["#Provide the Subscription ID of your existing Azure subscription\nsubscription_id = \"e223f1b3-d19b-4cfa-98e9-bc9be62717bc\"#\"<you-azure-subscription-id>\"\n\n#Provide a name for the new Resource Group that will contain Azure ML related services \nresource_group = \"AI-Practice-Dev-EastUS\"#\"<resource-group-name>\"\n\n# Proivde the name and region for the Azure Machine Learning Workspace that will be created\nworkspace_name = \"azure-ml-ws-zst\"#\"<azure-ml-workspace-name>\"\nworkspace_region = \"eastus2\"#'eastus2' # eastus, westcentralus, southeastasia, australiaeast, westeurope"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":7},{"cell_type":"markdown","source":["#Create an Azure ML Workspace"],"metadata":{}},{"cell_type":"markdown","source":["Run the following cell and follow the instructions printed in the output. \n\nYou will see instructions that read:\n\n`Performing interactive authentication. Please follow the instructions on the terminal.`\n\n`To sign in, use a web browser to open the page https://microsoft.com/devicelogin and enter the code SOMECODE to authenticate.`\n\nWhen you see this, open a new browser window, navigate to the provided URL. At the code prompt, enter the code provided (be sure to delete any trailing spaces).\n\nLogin with the same credentials you use to access your Azure subscription.\n\nOnce you have authenticated, the output will continue.\n\nWhen you see `Provisioning complete.` your Workspace has been created and you can move on to the next cell."],"metadata":{}},{"cell_type":"code","source":["import azureml.core\n\n# import the Workspace class and check the azureml SDK version\nfrom azureml.core import Workspace\n\nws = Workspace.create(\n    name = workspace_name,\n    subscription_id = subscription_id,\n    resource_group = resource_group, \n    location = workspace_region)\n\nprint(\"Provisioning complete.\")"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Performing interactive authentication. Please follow the instructions on the terminal.\nTo sign in, use a web browser to open the page https://microsoft.com/devicelogin and enter the code B6HWJ8TV6 to authenticate.\nInteractive authentication successfully completed.\nProvisioning complete.\n</div>"]}}],"execution_count":10},{"cell_type":"markdown","source":["#Persist the Workspace configuration"],"metadata":{}},{"cell_type":"markdown","source":["Run the following cells to retrieve the configuration of the deployed Workspace and persist it to local disk and then to the Databricks Filesystem."],"metadata":{}},{"cell_type":"code","source":["import os\nimport shutil\nimport azureml.core\n# import the Workspace class and check the azureml SDK version\nfrom azureml.core import Workspace\n\nws = Workspace(\n    workspace_name = workspace_name,\n    subscription_id = subscription_id,\n    resource_group = resource_group)\n\n# persist the subscription id, resource group name, and workspace name in aml_config/config.json.\naml_config = 'aml_config'\nif os.path.isfile(aml_config) or os.path.isdir(aml_config):\n    shutil.rmtree(aml_config)\nws.write_config()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Performing interactive authentication. Please follow the instructions on the terminal.\nTo sign in, use a web browser to open the page https://microsoft.com/devicelogin and enter the code BMNRLMTNX to authenticate.\nInteractive authentication successfully completed.\nWrote the config file config.json to: /databricks/driver/aml_config/config.json\n</div>"]}}],"execution_count":13},{"cell_type":"markdown","source":["Take a look at the contents of the generated configuration file by running the following cell:"],"metadata":{}},{"cell_type":"code","source":["%sh\ncat /databricks/driver/aml_config/config.json"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">{\n    &quot;resource_group&quot;: &quot;AI-Practice-Dev-EastUS&quot;,\n    &quot;subscription_id&quot;: &quot;e223f1b3-d19b-4cfa-98e9-bc9be62717bc&quot;,\n    &quot;workspace_name&quot;: &quot;azure-ml-ws-zst&quot;\n}</div>"]}}],"execution_count":15},{"cell_type":"markdown","source":["Copy the config file to DBFS"],"metadata":{}},{"cell_type":"code","source":["#persist the config file to dbfs so that it can be used for the other notebooks.\naml_config_local = 'file:' + os.getcwd() + '/' + aml_config\naml_config_dbfs = '/dbfs/' + 'aml_config'\n\nif os.path.isfile(aml_config_dbfs) or os.path.isdir(aml_config_dbfs):\n    shutil.rmtree(aml_config_dbfs)\n    #dbutils.fs.rm(aml_config, recurse=True)\n\ndbutils.fs.cp(aml_config_local, aml_config, recurse=True)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">6</span><span class=\"ansired\">]: </span>True\n</div>"]}}],"execution_count":17},{"cell_type":"markdown","source":["#Deploy model to Azure Container Instance (ACI)"],"metadata":{}},{"cell_type":"markdown","source":["In this notebook, you will deploy the best performing model you selected previously as a web service hosted in Azure Container Service."],"metadata":{}},{"cell_type":"markdown","source":["## Copy the model from DBFS"],"metadata":{}},{"cell_type":"markdown","source":["You previously saved the model in DBFS, but to deploy it using Azure Machine Learning services, you will need to copy the model to local storage on the driver node.\n\nRun the following cells to copy the model from DBFS to local and verify that you can load the model."],"metadata":{}},{"cell_type":"code","source":["##NOTE: service deployment always gets the model from the current working dir. \ntempFolderName = '/FileStore/ignite2018_05_03_{0}'.format(\"8fbaedaa-07f8-4259-85e5-19c4c122a869\") # UUID from previous notebook\nfileName1 = '{0}/claim_classifier.tfl.data-00000-of-00001'.format(tempFolderName)\nfileName2 = '{0}/claim_classifier.tfl.index'.format(tempFolderName)\nfileName3 = '{0}/claim_classifier.tfl.meta'.format(tempFolderName)\n\nmodel_name = \"claim_classifier.tfl\"\nmodel_path_dbfs = fileName1 #os.path.join(\"/dbfs/models\", model_name)\nmodel_path_local = \"file:\" + os.getcwd() + \"/\" + model_name + \"/\"\n\nprint(\"copy model from dbfs {} to under local folder {}\".format(model_path_dbfs, model_path_local))\nos.mkdir(\"/databricks/driver/claim_classifier.tfl\")\ndbutils.fs.cp(fileName1, model_path_local, recurse=False)\ndbutils.fs.cp(fileName2, model_path_local, recurse=False)\ndbutils.fs.cp(fileName3, model_path_local, recurse=False)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">copy model from dbfs /FileStore/ignite2018_05_03_8fbaedaa-07f8-4259-85e5-19c4c122a869/claim_classifier.tfl.data-00000-of-00001 to under local folder file:/databricks/driver/claim_classifier.tfl/\n<span class=\"ansired\">Out[</span><span class=\"ansired\">19</span><span class=\"ansired\">]: </span>True\n</div>"]}}],"execution_count":22},{"cell_type":"code","source":["os.listdir(\"/databricks/driver/claim_classifier.tfl\")"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">20</span><span class=\"ansired\">]: </span>\n[&apos;claim_classifier.tfl.data-00000-of-00001&apos;,\n &apos;.claim_classifier.tfl.data-00000-of-00001.crc&apos;,\n &apos;.claim_classifier.tfl.index.crc&apos;,\n &apos;.claim_classifier.tfl.meta.crc&apos;,\n &apos;claim_classifier.tfl.index&apos;,\n &apos;claim_classifier.tfl.meta&apos;]\n</div>"]}}],"execution_count":23},{"cell_type":"markdown","source":["# Register the model with Azure Machine Learning"],"metadata":{}},{"cell_type":"markdown","source":["Begin by loading your Azure Machine Learning Workspace configuration from disk."],"metadata":{}},{"cell_type":"code","source":["import azureml.core\nfrom azureml.core.workspace import Workspace\n\n#get the config file from dbfs\naml_config = '/aml_config'\ndbutils.fs.cp(aml_config, 'file:'+os.getcwd()+aml_config, recurse=True)\n\nws = Workspace.from_config()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Found the config file in: /databricks/driver/aml_config/config.json\n</div>"]}}],"execution_count":26},{"cell_type":"markdown","source":["In the following, you register the model file with Azure Machine Learning (which saves a copy of the model in the cloud)."],"metadata":{}},{"cell_type":"code","source":["#Register the model\nfrom azureml.core.model import Model\nmymodel = Model.register(model_path = model_name + \"/\", # this points to a local file or folder in the current working dir\n                       model_name = model_name, # this is the name the model is registered with                 \n                       description = \"Claims classification model.\",\n                       workspace = ws)\n\nprint(mymodel.name, mymodel.description, mymodel.version)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Registering model claim_classifier.tfl\nclaim_classifier.tfl Claims classification model. 4\n</div>"]}}],"execution_count":28},{"cell_type":"markdown","source":["#Create the scoring web service"],"metadata":{}},{"cell_type":"markdown","source":["When deploying models for scoring with Azure Machine Learning services, you need to define the code for a simple web service that will load your model and use it for scoring. By convention this service has two methods `init` which loads the model and `run` which scores data using the loaded model. \n\nThis scoring service code will later be deployed inside of a specially prepared Docker container."],"metadata":{}},{"cell_type":"code","source":["#%%writefile score_classifer.py\nscore_classifier = \"\"\"\n\nimport numpy as np\nimport re\nimport tensorflow as tf\nimport tflearn\nfrom tflearn.data_utils import to_categorical\nimport nltk\nimport uuid\nimport json\nimport os\nimport sys\n\ndef init():\n    try:\n        print(\"init() called.\")\n        \n        global model2\n        global net2\n        global vectorizer\n        \n        # Takes at most a couple of minutes to download all NLTK content\n        print(\"downloading nltk.\")\n        nltk.download(\"all\")\n        \n        tempFolderName = './resources'\n        os.mkdir(tempFolderName)\n        print('Content files will be saved to {0}'.format(tempFolderName))\n\n        print(\"downloading files...\")\n        filesToDownload = ['claims_labels.txt', 'claims_text.txt', 'contractions.py', 'textanalytics.py']\n        for fileToDownload in filesToDownload:\n          downloadCommand = 'wget -O ''{0}/{1}'' ''https://databricksdemostore.blob.core.windows.net/data/05.03/{1}'''.format(tempFolderName, fileToDownload)\n          print(downloadCommand)\n          os.system(downloadCommand)\n        print(\"file download complete.\")\n        \n        print(\"importing textanalytics...\")\n        sys.path.append(os.path.abspath('./{0}'.format(tempFolderName)))      \n        import textanalytics as ta\n        print(\"importing succeeded.\")\n        \n        \n        claims_corpus = [claim for claim in open(\"claims_text.txt\")]\n\n        norm_corpus = ta.normalize_corpus(claims_corpus)\n        vectorizer, tfidf_matrix = ta.build_feature_matrix(norm_corpus) \n        \n        print(\"creating network\")\n        # Build the neural network and then load its weights from disk\n        net2 = tflearn.input_data(shape=[None, 258])\n        net2 = tflearn.fully_connected(net2, 32)\n        net2 = tflearn.fully_connected(net2, 32)\n        net2 = tflearn.fully_connected(net2, 2, activation='softmax')\n        net2 = tflearn.regression(net2)\n        \n        print(\"loading model from disk...\")\n        from azureml.core.model import Model\n        model2 = tflearn.DNN(net2)\n        model_name = \"claim_classifier.tfl\" \n        model_path = Model.get_model_path(model_name)\n        model2.load(model_path, weights_only=True)\n        print(\"model loaded.\")\n        \n        print(\"init complete.\")\n\n    except Exception as e:\n        print(\"Exception in init: \" + str(e))\n        trainedModel = e\n\ndef run(input_df):\n    response = ''    \n\n    try:\n        print(\"calling run with: \" + input_df)     \n        \n        \n        print(\"importing textanalytics...\")\n        import textanalytics as ta\n        \n        print(\"using hard coded values\")\n        test_claim = ['I crashed my car into a pole.', 'The flood ruined my house.', 'I lost control of my car and fell in the river.']\n        test_claim = ta.normalize_corpus(test_claim)\n        test_claim = vectorizer.transform(test_claim)\n        test_claim = test_claim.toarray()\n        \n        print(\"calling model2.predict_label\")\n        preds = model2.predict_label(test_claim)\n        \n        response = json.dumps(preds)\n        \n        print(\"response: \" + str(response))\n        \n    except Exception as e:\n        print(\"Exception in run: \" + str(e))\n        return (str(e))\n\n    # Return results\n    return response\n    \n\"\"\"\n\nexec(score_classifier)\n\nwith open(\"score_classifier.py\", \"w\") as file:\n    file.write(score_classifier)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":31},{"cell_type":"code","source":["import numpy as np\nimport re\nimport tensorflow as tf\nimport tflearn\nfrom tflearn.data_utils import to_categorical\nimport nltk\nimport uuid\nimport json\nimport os\nimport sys\n\ndef init():\n    try:\n        print(\"init() called.\")\n        \n        global model2\n        global net2\n        global vectorizer\n        \n        # Takes at most a couple of minutes to download all NLTK content\n        print(\"downloading nltk.\")\n        nltk.download(\"all\")\n        \n        tempFolderName = './resources'\n        os.mkdir(tempFolderName)\n        print('Content files will be saved to {0}'.format(tempFolderName))\n\n        print(\"downloading files...\")\n        filesToDownload = ['claims_labels.txt', 'claims_text.txt', 'contractions.py', 'textanalytics.py']\n        for fileToDownload in filesToDownload:\n          downloadCommand = 'wget -O ''{0}/{1}'' ''https://databricksdemostore.blob.core.windows.net/data/05.03/{1}'''.format(tempFolderName, fileToDownload)\n          print(downloadCommand)\n          os.system(downloadCommand)\n        print(\"file download complete.\")\n        \n        print(\"importing textanalytics...\")\n        sys.path.append(os.path.abspath('./{0}'.format(tempFolderName)))      \n        import textanalytics as ta\n        print(\"importing succeeded.\")\n        \n        \n        claims_corpus = [claim for claim in open(\"claims_text.txt\")]\n\n        norm_corpus = ta.normalize_corpus(claims_corpus)\n        vectorizer, tfidf_matrix = ta.build_feature_matrix(norm_corpus) \n        \n        print(\"creating network\")\n        # Build the neural network and then load its weights from disk\n        net2 = tflearn.input_data(shape=[None, 258])\n        net2 = tflearn.fully_connected(net2, 32)\n        net2 = tflearn.fully_connected(net2, 32)\n        net2 = tflearn.fully_connected(net2, 2, activation='softmax')\n        net2 = tflearn.regression(net2)\n        \n        print(\"loading model from disk...\")\n        from azureml.core.model import Model\n        model2 = tflearn.DNN(net2)\n        model_name = \"claim_classifier.tfl\" \n        model_path = Model.get_model_path(model_name)\n        model2.load(model_path, weights_only=True)\n        print(\"model loaded.\")\n        \n        print(\"init complete.\")\n\n    except Exception as e:\n        print(\"Exception in init: \" + str(e))\n        trainedModel = e\n\ndef run(input_df):\n    response = ''    \n\n    try:\n        print(\"calling run with: \" + input_df)     \n        \n        \n        print(\"importing textanalytics...\")\n        import textanalytics as ta\n        \n        print(\"using hard coded values\")\n        test_claim = ['I crashed my car into a pole.', 'The flood ruined my house.', 'I lost control of my car and fell in the river.']\n        test_claim = ta.normalize_corpus(test_claim)\n        test_claim = vectorizer.transform(test_claim)\n        test_claim = test_claim.toarray()\n        \n        print(\"calling model2.predict_label\")\n        preds = model2.predict_label(test_claim)\n        \n        response = json.dumps(preds)\n        \n        print(\"response: \" + str(response))\n        \n    except Exception as e:\n        print(\"Exception in run: \" + str(e))\n        return (str(e))\n\n    # Return results\n    return response"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":32},{"cell_type":"markdown","source":["# Create a Conda dependencies environment file"],"metadata":{}},{"cell_type":"markdown","source":["Your scoring service can have dependencies install by using a Conda environment file. Items listed in this file will be conda or pip installed within the Docker container that is created and thus be available to your scoring web service logic."],"metadata":{}},{"cell_type":"code","source":["from azureml.core.conda_dependencies import CondaDependencies \n\nmyacienv = CondaDependencies.create(conda_packages=['scikit-learn','numpy','pandas'], pip_packages=['nltk','tensorflow','tflearn'])\n\nwith open(\"mydeployenv.yml\",\"w\") as f:\n    f.write(myacienv.serialize_to_string())"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":35},{"cell_type":"markdown","source":["#Deployment"],"metadata":{}},{"cell_type":"markdown","source":["In the following cells you will use the Azure Machine Learning SDK to package the model and scoring script in a container, and deploy that container to an Azure Container Instance.\n\nRun the following cells."],"metadata":{}},{"cell_type":"markdown","source":["Create a configuration of the ACI web service instance that provides the number of CPU cores, size of memory, a collection of tags and a description."],"metadata":{}},{"cell_type":"code","source":["from azureml.core.webservice import AciWebservice, Webservice\n\naci_config = AciWebservice.deploy_configuration(\n    cpu_cores = 1, \n    memory_gb = 1, \n    tags = {'name':'Claim Classification'}, \n    description = 'Classifies a claim as home or auto.')"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":39},{"cell_type":"markdown","source":["Next, build up a container image configuration that names the scoring service script, the runtime (python or Spark), and provides the conda file."],"metadata":{}},{"cell_type":"code","source":["service_name = \"claimclassservice10\"\nruntime = \"python\" #\"python\" #\ndriver_file = \"score_classifier.py\"\nconda_file = \"mydeployenv.yml\"\n\nfrom azureml.core.image import ContainerImage\n\nimage_config = ContainerImage.image_configuration(execution_script = driver_file,\n                                                  runtime = runtime,\n                                                  conda_file = conda_file)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":41},{"cell_type":"markdown","source":["Now you are ready to begin your deployment to the Azure Container Instance. \n\nRun the following cell. This may take between **5-15 minutes** to complete.\n\nYou will see output similar to the following when your web service is ready:\n`SucceededACI service creation operation finished, operation \"Succeeded\"`"],"metadata":{}},{"cell_type":"code","source":["webservice = Webservice.deploy_from_model(\n  workspace=ws, \n  name=service_name, \n  deployment_config=aci_config,\n  models = [mymodel], \n  image_config=image_config, \n  )\n\nwebservice.wait_for_deployment(show_output=True)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Creating image\nImage creation operation finished for image claimclassservice10:1, operation &quot;Succeeded&quot;\nCreating service\nRunning............................................\nSucceededACI service creation operation finished, operation &quot;Succeeded&quot;\n</div>"]}}],"execution_count":43},{"cell_type":"markdown","source":["#Test the deployed service"],"metadata":{}},{"cell_type":"markdown","source":["Now you are ready to test scoring using the deployed web service. The following cell invokes the web service. \n\nRun the following cells to test scoring using a single input row against the deployed web service."],"metadata":{}},{"cell_type":"code","source":["test_claim = ['I crashed my car into a pole.', 'The flood ruined my house.', 'I lost control of my car and fell in the river.']"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":46},{"cell_type":"code","source":["import json\njson_str_test_inputs = json.dumps(test_claim)\nwebservice.run(input_data = json_str_test_inputs)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">35</span><span class=\"ansired\">]: </span>&quot;\\n**********************************************************************\\n  Resource &apos;corpora/stopwords&apos; not found.  Please use the NLTK\\n  Downloader to obtain the resource:  &gt;&gt;&gt; nltk.download()\\n  Searched in:\\n    - &apos;/home/mmlspark/nltk_data&apos;\\n    - &apos;/usr/share/nltk_data&apos;\\n    - &apos;/usr/local/share/nltk_data&apos;\\n    - &apos;/usr/lib/nltk_data&apos;\\n    - &apos;/usr/local/lib/nltk_data&apos;\\n**********************************************************************&quot;\n</div>"]}}],"execution_count":47},{"cell_type":"markdown","source":["#Clean up"],"metadata":{}},{"cell_type":"markdown","source":["When you are finished experimenting with your deployed web service, you can also use the Azure Machine Learning Python SDK to delete the deployed service.\n\nRun the following cell to cleanup."],"metadata":{}},{"cell_type":"code","source":["webservice.delete()"],"metadata":{},"outputs":[],"execution_count":50},{"cell_type":"markdown","source":["# You are done!"],"metadata":{}},{"cell_type":"markdown","source":["Congratulations, you have completed this team challenge!"],"metadata":{}}],"metadata":{"name":"03 Deploy Classifier Web Service","notebookId":2562790992885097},"nbformat":4,"nbformat_minor":0}